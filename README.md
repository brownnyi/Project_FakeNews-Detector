# 가짜뉴스 탐지 프로젝트
## 목적
- 오늘날 많은 사람들이 가짜뉴스에 쉽게 노출되어 그에 따른 피해가 생기는 것을 보고, ‘가짜뉴스를 찾아내는 모델’을 만드는 프로젝트 기획

## 프로젝트 개요
- 초기 BERT 모델을 통해 가짜뉴스의 *특징들로 분류된 데이터를 학습시켜 가짜뉴스 탐지를 하고자 하였지만, 일정한 특징들을 갖지 않고 '날조'된 기사들을 찾으려면 다른 방법을 찾아야겠다는 생각에 초기모델 포기
- LLM모델(Llama2-Koalpaca)을 가짜뉴스 데이터 파인튜닝하여 가짜뉴스의 전문이나 제목을 질문했을때 대답의 정확도가 높은가를 알아보는 프로젝트
- 이전 프로젝트 유튜브 API를 활용한 동영상 스크립트 저장 코드와 네이버 뉴스 크롤링 코드를 같이 사용하여 데이터 수집

## 한계점
- 가상 클라우드 컴퓨터를 사용했더라면 더 큰 데이터를 학습시킬 수 있었겠지만, Colab 유료계정 환경으로도 데이터를 학습시키는데 한계가 존재
- 데이터의 신뢰성 문제(내가 수집한 뉴스 데이터가 과연 신뢰할 수 있는가?)

## 개선점
- AWS와 같은 가상 클라우드 컴퓨터를 사용하여 더 많은 양의 데이터를 파인튜닝하여 정확도를 높일 수 있을 것이라고 예상
- 데이터의 신뢰성 문제는 '서울대학교 팩트체크'와 같이 진짜뉴스와 가짜뉴스를 판별하는 사이트를 크롤링 하여 데이터를 얻는다면 신뢰성을 얻을 수 있을 것이라고 확신

*Ai-Hub를 통해 얻은 낚시성 기사 탐지 데이터들은

![image](https://github.com/user-attachments/assets/ca5c8a31-72cb-42b8-9ead-d9f7a7f0c47a)

이와 같은 형태로 제목과 본문의 불일치 기사, 본문의 도메인의 일관성 부족 기사 들의 특징을 가지고 있는 데이터
